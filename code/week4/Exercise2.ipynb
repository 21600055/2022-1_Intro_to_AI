{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b192ca6b",
   "metadata": {},
   "source": [
    "HW_3_21600055 김동규\n",
    "\n",
    "exercise2\n",
    "\n",
    "1. Objective: natural language process lab,  \n",
    "\n",
    "2. input: string data with html tag\n",
    "\n",
    "3. output: print encoded data with integer frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ff14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f683b25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><h2>What is nlp??? </h2></html> \\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_data = \"\"\"<html><h2>What is nlp??? </h2></html> \n",
    "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
    "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
    "(In this post), you will discover what natural language processing is and why it is so important.\n",
    "After reading this post, you will know => What natural language is and how it is different from other types of data.\"\"\"\n",
    "str_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb93be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp???  \n",
      "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
      "(In this post), you will discover what natural language processing is and why it is so important.\n",
      "After reading this post, you will know => What natural language is and how it is different from other types of data.\n"
     ]
    }
   ],
   "source": [
    "def remove_html(text_data): # remove html tag function\n",
    "    soup = BeautifulSoup(text_data,\"lxml\")\n",
    "    return soup.get_text()\n",
    "\n",
    "processed_text = remove_html(str_data)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0abec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp  \n",
      "Natural Language Processing or NLP for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "In this post you will discover what natural language processing is and why it is so important\n",
      "After reading this post you will know  What natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text): #remove punctuation like (),!,? ..\n",
    "    sent = []\n",
    "    for t in text.split(' '): # split with \" \"\n",
    "        no_punct = \"\".join([c for c in t if c not in string.punctuation]) # slice each spelling c if c is not punctuation\n",
    "        sent.append(no_punct)\n",
    "    sentence = \" \".join(s for s in sent) # join each punctuation eliminated word\n",
    "    return sentence\n",
    "\n",
    "rmv_punc_sentence = remove_punctuation(processed_text)\n",
    "print(rmv_punc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b234976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is nlp  \n",
      "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "in this post you will discover what natural language processing is and why it is so important\n",
      "after reading this post you will know  what natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "lower_sentence = rmv_punc_sentence.lower() # change from uppercase to lowercase\n",
    "print(lower_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4621ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "npl = spacy.load('en_core_web_sm')\n",
    "doc = npl(lower_sentence.strip())  # token object doc, and it holds liguistic features and relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2682f49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'be',\n",
       " 'nlp',\n",
       " ' \\n',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'or',\n",
       " 'nlp',\n",
       " 'for',\n",
       " 'short',\n",
       " 'be',\n",
       " 'broadly',\n",
       " 'define',\n",
       " 'as']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sentence = [token.lemma_ for token in doc] # change token lemmatization \n",
    "tok_lem_sentence[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f69cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cea0bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words('english')[:10])\n",
    "print(len(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "543aabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing stopwords: \n",
      " ['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum']\n",
      "\n",
      "After removing stopwords: \n",
      " ['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "\n",
      "Removed word:  {'you', 'for', 'it', 'in', 'why', 'more', 'will', 'so', 'than', 'from', 'how', 'what', 'after', 'and', 'other', 'as', 'this', 'with', 'be', 'or', 'have', 'out', 'by', 'the', 'of'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # stop word set\n",
    "\n",
    "print(\"Before removing stopwords: \\n\",tok_lem_sentence)\n",
    "rmv_sw_sentence = [w for w in tok_lem_sentence if not w in stop_words] # cut the stop words\n",
    "print(\"\\nAfter removing stopwords: \\n\",rmv_sw_sentence)\n",
    "removed_word = [w for w in tok_lem_sentence if not w in rmv_sw_sentence]\n",
    "print(\"\\nRemoved word: \",set(removed_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43211353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dictionary = {} # to save frequency of words\n",
    "\n",
    "def make_frequency_dict(text):\n",
    "    for word in text:\n",
    "        if word not in dictionary: # if there is no words, make key and value\n",
    "            dictionary[word] = 0\n",
    "        dictionary[word] += 1 # if exists, plus one value\n",
    "make_frequency_dict(rmv_sw_sentence)\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b8f538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 2,\n",
       " ' \\n': 1,\n",
       " 'natural': 5,\n",
       " 'language': 5,\n",
       " 'processing': 3,\n",
       " 'short': 1,\n",
       " 'broadly': 1,\n",
       " 'define': 1,\n",
       " 'automatic': 1,\n",
       " 'manipulation': 1,\n",
       " 'like': 1,\n",
       " 'speech': 1,\n",
       " 'text': 1,\n",
       " 'software': 1,\n",
       " '\\n': 3,\n",
       " 'study': 1,\n",
       " 'around': 1,\n",
       " '50': 1,\n",
       " 'year': 1,\n",
       " 'grow': 1,\n",
       " 'field': 1,\n",
       " 'linguistic': 1,\n",
       " 'rise': 1,\n",
       " 'computer': 1,\n",
       " 'post': 2,\n",
       " 'discover': 1,\n",
       " 'important': 1,\n",
       " 'read': 1,\n",
       " 'know': 1,\n",
       " ' ': 1,\n",
       " 'different': 1,\n",
       " 'type': 1,\n",
       " 'datum': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef79d963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 5),\n",
       " ('language', 5),\n",
       " ('processing', 3),\n",
       " ('\\n', 3),\n",
       " ('nlp', 2),\n",
       " ('post', 2),\n",
       " (' \\n', 1),\n",
       " ('short', 1),\n",
       " ('broadly', 1),\n",
       " ('define', 1),\n",
       " ('automatic', 1),\n",
       " ('manipulation', 1),\n",
       " ('like', 1),\n",
       " ('speech', 1),\n",
       " ('text', 1),\n",
       " ('software', 1),\n",
       " ('study', 1),\n",
       " ('around', 1),\n",
       " ('50', 1),\n",
       " ('year', 1),\n",
       " ('grow', 1),\n",
       " ('field', 1),\n",
       " ('linguistic', 1),\n",
       " ('rise', 1),\n",
       " ('computer', 1),\n",
       " ('discover', 1),\n",
       " ('important', 1),\n",
       " ('read', 1),\n",
       " ('know', 1),\n",
       " (' ', 1),\n",
       " ('different', 1),\n",
       " ('type', 1),\n",
       " ('datum', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sorted = sorted(dictionary.items(),key = lambda x:x[1], reverse = True) # make a frequency dictionary and sort\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a889eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0 # dictionary frequency value\n",
    "for (word,frequency) in vocab_sorted:\n",
    "    if frequency > 1 : # remove if frequency is less than 2\n",
    "        i += 1\n",
    "        word_to_index[word] = i # make dictionary\n",
    "print(word_to_index) # natural has most frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8981bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6, 'OOV': 7}\n"
     ]
    }
   ],
   "source": [
    "word_to_index[\"OOV\"] = len(word_to_index) + 1\n",
    "print(word_to_index) # unknown word with frequency 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "360da4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "[5, 7, 1, 2, 3, 5, 7, 7, 7, 7, 7, 1, 2, 7, 7, 7, 7, 4, 7, 1, 2, 3, 7, 7, 7, 7, 7, 7, 7, 7, 4, 6, 7, 1, 2, 3, 7, 4, 7, 6, 7, 7, 1, 2, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "encoded = [] # encode list\n",
    "print(rmv_sw_sentence)\n",
    "\n",
    "for w in rmv_sw_sentence: # loop for removed stop words sentence\n",
    "    encoded.append(word_to_index.get(w,word_to_index[\"OOV\"])) # get from dictionary each word key and value if w is not in dictionary, get OOV key\n",
    "\n",
    "print(encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
